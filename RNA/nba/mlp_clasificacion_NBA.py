# -*- coding: utf-8 -*-
"""Copia de MLP-ClasificacionNBA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wPf3QBJssNaHrL1owYPw8_mp06vJY0Cs

Integrantes: Carcelen Jorge , Pulamarin Brayan , Ruiz Mauricio

**Importar Módulos**
"""

import matplotlib.pyplot as plt
from sklearn import preprocessing 
import numpy as np
from keras.models import Sequential
from keras.layers.core import Dense
import pandas as pd
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import r2_score
from sklearn.metrics import roc_curve
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
import tensorflow as tf
import time

"""**Cargar los Datos**"""

dataset= pd.read_csv("wine.csv")
datos = dataset.values
datos.shape

dim = 12;
# from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(datos[:, 0:dim])
datos[:, 0:dim] = imputer.transform(datos[:, 0:dim])

datos_min_max = preprocessing.MinMaxScaler().fit_transform(datos)

datos_min_max


datos_normalizer = preprocessing.Normalizer().transform(datos.T)
datos_normalizer = datos_normalizer.T
datos_normalizer

datos_robust_scaler = preprocessing.RobustScaler().fit_transform(datos)
datos_robust_scaler

datos_standard_scaler = preprocessing.StandardScaler().fit_transform(datos)
datos_standard_scaler

"""**Comparación de métodos**"""

# crea una figura con 5 subfiguras para comparar los métodos
fig = plt.figure(figsize=(20, 5))
ax1 = fig.add_subplot(1, 5, 1)
ax2 = fig.add_subplot(1, 5, 2)
ax3 = fig.add_subplot(1, 5, 3)
ax4 = fig.add_subplot(1, 5, 4)
ax5 = fig.add_subplot(1, 5, 5)

# crea y personaliza series de datos
ax1.set_title("Datos")
ax1.plot(datos, linewidth=0, marker="*", color="red", markersize=4)

ax2.set_title("Min Max")
ax2.plot(datos_min_max, linewidth=0, marker="*", color="blue", markersize=4)

ax3.set_title("Normalizer")
ax3.plot(datos_normalizer, linewidth=0, marker="*", color="green", markersize=4)
#ax3.set_ylim(0, 1)

ax4.set_title("Standard Scaler")
ax4.plot(datos_standard_scaler, linewidth=0, marker="*", color="orange", markersize=4)

ax5.set_title("Robust Scaler")
ax5.plot(datos_robust_scaler, linewidth=0, marker="*", color="black", markersize=4)
plt.savefig("comparacion-metodos")
plt.show()

"""**Dividir los datos para training set y test set**"""

entrada = datos_min_max[:,0:dim]
salida = datos_min_max[:,dim]
# cargamos los datos
training_data = np.array(entrada, "float32")
# ground truth
target_data = np.array(salida, "float32")

trainX, testX, trainy, testy = train_test_split(training_data, target_data ,test_size=0.3)



"""**Establecer los parametros del modelo**"""

opt = tf.keras.optimizers.SGD(learning_rate=0.001 , momentum=0.3)
model = Sequential()
model.add(Dense(15, activation='relu', input_dim=dim))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

start_time = time.time()


data_modelo = model.fit(trainX, trainy, validation_data=(testX,testy),epochs=50, batch_size=30)
print ("\nTime (sec):", time.time() - start_time)

"""**Evaluar el modelo**"""

# evaluamos el modelo
print("Evaluación del modelo test")
scores_test = model.evaluate(testX, testy)
print("\%s: %.4f" % (model.metrics_names[0], scores_test[0])) # loss
print("\n%s: %.2f%%" % (model.metrics_names[1], scores_test[1]*100)) # accuracy

print("Evaluación del modelo training")
scores = model.evaluate(trainX, trainy)
print("\%s: %.4f" % (model.metrics_names[0], scores[0])) # loss
print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100)) # accuracy

# full metrics
y_pred = model.predict(testX).round()
y_true = testy.round()

"""**Matriz de confusión**"""


# Matriz de confusión:
cm = confusion_matrix(y_true, y_pred)
print(cm)
plt.figure(figsize = (8,4))
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Prediction', fontsize = 12)
plt.ylabel('Real', fontsize = 12)
plt.savefig("matriz de confusion")
plt.show()

"""**Calcular de las métricas**"""

# Exactitud:
acc = accuracy_score(y_true, y_pred)
print("Accuracy: " + "{0:.2}".format(acc))
# Sensibilidad:
rec = recall_score(y_true, y_pred)
print("Recall: " + "{0:.2}".format(rec))
# Especificidad:
esp=recall_score(y_true, y_pred, pos_label=0)
print("Especificity: " + "{0:.2}".format(esp))
# Precisión:
prec = precision_score(y_true, y_pred)
print("Precision: " + "{0:.2}".format(prec))
# Puntuación F1:
f1 = f1_score(y_true, y_pred)
print("F1 Score: " + "{0:.2}".format(f1))
# Área bajo la curva:
auc = roc_auc_score(y_true,y_pred)
print("Area bajo de la curva: " + "{0:.2}".format(auc))
# R Score:(R^2 coefficient of determination)
r2 = r2_score(y_true, y_pred)
print("R2: " + "{0:.2}".format(r2))

"""**Curva ROC**"""

# Curva ROC

lw = 2
plt.plot(roc_curve(y_true, y_pred)[0], roc_curve(y_true, y_pred)[1], color='darkred',lw=lw, label='ROC curve (area = %0.2f)'%auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

"""**Graficas de Training y Test**"""

acc = data_modelo.history['accuracy']

print(acc)
val_acc  = data_modelo.history['val_accuracy']
loss     = data_modelo.history['loss']
val_loss = data_modelo.history['val_loss']
epochs   = range(1,len(acc)+1,1)

plt.plot ( epochs,     acc, 'r--', label='Training Exactitud'  )
plt.plot ( epochs, val_acc,  'b', label='Validation Exactitud')
plt.title ('Training  y Validation Exactitud')
plt.ylabel('Accuracy')
plt.xlabel('epochs')
plt.legend()
plt.show()

plt.plot ( epochs,     loss, 'r--',label='Training Perdida' )
plt.plot ( epochs, val_loss ,  'b' , label='Validation Perdida')
plt.title ('Training y Validation Perdida '   )
plt.ylabel('Loss') # corregir por perdida
plt.xlabel('epochs')
plt.legend()
plt.show()

